{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Perceptron Lernalgorithmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from numpy import array, dot, zeros\n",
    "from numpy import random as rndm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "heaviside = lambda x: 0 if x < 0 else 1\n",
    "\n",
    "def fit(iterations, training_data_set,w):\n",
    "   \n",
    "    errors2 = []\n",
    "    weights2 = []\n",
    "    for i in range(iterations):\n",
    "\n",
    "        training_data = random.choice(training_data_set)\n",
    "        x = training_data[0] \n",
    "        y = training_data[1] \n",
    "\n",
    "        y_hat = heaviside(dot(w, x))\n",
    "        error = y - y_hat\n",
    "        \n",
    "        errors2.append(error)    \n",
    "        weights2.append(w)        \n",
    "        w += error * x\n",
    "        \n",
    "    return errors2, weights2\n",
    "\n",
    "def main():\n",
    "        \n",
    "    training_data_set = [\n",
    "        (array([1,0,0]), 0),\n",
    "        (array([1,0,1]), 1),\n",
    "        (array([1,1,0]), 1),\n",
    "        (array([1,1,1]), 1)]  \n",
    "  \n",
    "    rndm.seed( 12 )\n",
    "  \n",
    "    w = zeros(3)\n",
    "  \n",
    "    iterations = 30\n",
    "    errors, weights = fit(iterations, training_data_set,w) \n",
    "    \n",
    "    w = weights[iterations-1]\n",
    "    print(\"Gewichtsvektor am Ende des Trainings:\")\n",
    "    print(w)\n",
    "    \n",
    "    print(\"Auswertung am Ende des Trainings:\")\n",
    "    for x, y in training_data_set:\n",
    "        y_hat2 = heaviside(dot(x, w))\n",
    "        \n",
    "        print(\"{}: {} -> {}\".format(x, y, y_hat2)) \n",
    "   \n",
    "    \n",
    "    \n",
    "    fignr = 1\n",
    "    \n",
    "    plt.figure(fignr,figsize=(5,5), facecolor='grey')\n",
    "    plt.axes().set_facecolor('grey')    \n",
    "    plt.plot(errors,color='black')\n",
    "    plt.style.use('seaborn-whitegrid')    \n",
    "    plt.xlabel('Iteration')    \n",
    "    plt.ylabel(r\"$(y - \\hat y)$\") \n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted, check_random_state\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class AperceptronEstimator(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, n_iterations=20, random_state=None):\n",
    "       \n",
    "\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.errors = []\n",
    "\n",
    "\n",
    "    def heaviside(self, x):\n",
    "        \n",
    "        if x < 0:\n",
    "            result = 0\n",
    "        else:\n",
    "            result = 1\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def fit(self, X=None, y=None ):\n",
    "        \"\"\" Trainieren       \n",
    "        X: Array-ähnliche Struktur mit [N,D], wobei \n",
    "           N = Zeilen = Anzahl der Lernbeispiele und \n",
    "           D = Spalten = Anzahl der Features \n",
    "        y: Array mit [N], mit N so wie oben        \n",
    "        \"\"\" \n",
    "        random_state = check_random_state(self.random_state)\n",
    "        self.w = random_state.random_sample(np.size(X,1))       \n",
    "        X, y = check_X_y(X, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y      \n",
    "        for i in range(self.n_iterations):\n",
    "            rand_index = random_state.randint(0,np.size(X,0))\n",
    "            x_ = X[rand_index]\n",
    "            y_ = y[rand_index]\n",
    "            y_hat = self.heaviside(np.dot(self.w, x_))\n",
    "            error = y_ - y_hat\n",
    "            self.errors.append(error)\n",
    "            self.w += error * x_\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\" Auswerten eines Vektors        \n",
    "        x: Ein Test Inputvektor         \n",
    "        \"\"\"   \n",
    "    \n",
    "    \n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "    \n",
    "        y_hat = self.heaviside(np.dot(self.w,x))\n",
    "\n",
    "        return y_hat\n",
    "    \n",
    "    \n",
    "    def plot(self):                 \n",
    "    \n",
    "        fignr = 1\n",
    "        plt.figure(fignr,figsize=(10,10),facecolor='grey')\n",
    "        plt.axes().set_facecolor('grey')\n",
    "    \n",
    "        plt.plot(self.errors,color='black')\n",
    "    \n",
    "        plt.style.use('seaborn-whitegrid')  \n",
    "        \n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel(r\"$(y - \\hat y)$\")\n",
    "\n",
    "def main():\n",
    "    \n",
    "    X = np.array([[1,0,0]\n",
    "                 ,[1,0,1],\n",
    "                  [1,1,0],\n",
    "                  [1,1,1]])\n",
    "    \n",
    "    y = np.array([0,1,1,1])\n",
    "    \n",
    "    Perceptron = AperceptronEstimator(30,10)\n",
    "    Perceptron.fit(X,y) \n",
    "    \n",
    "    for index, x in enumerate(X):\n",
    "        p = Perceptron.predict(x)\n",
    "        print(\"{}: {} -> {}\".format(x, y[index],p))\n",
    "        \n",
    "    Perceptron.plot()\n",
    "\n",
    "\n",
    "main()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Perceptron und Blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 4.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Daten erstellen für das Lernen mit Hilfe von scikit-learn\n",
    "# Wir erzeugen zwei Punkthaufen, mit zwei Kategorien, die linear trennbar sind\n",
    "# n_samples = Anzahl an Datenpunkten pro Kategorie\n",
    "# n_features = Anzahl der Kategorien\n",
    "# centers = Anzahl der Punkthaufen\n",
    "# random_state = Seed für Zufallsgenerator\n",
    "X, y = datasets.make_blobs(n_samples=100, n_features=2, centers=2,\\\n",
    "                           random_state=3)\n",
    "# Klassifikationen\n",
    "# Aufbau eines Raster, um auszuwerten und zu zeichnen\n",
    "s = 0.02  # Schrittweite im Raster\n",
    "# Ermittlung der 1-D Arrays, die die Koordinaten im Raster repräsentieren\n",
    "# Slices werden im Anhang A erläutert\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1 # erste Koordinate\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 # zweite Koordinate\n",
    "# np.arange liefert ein ndarray mit gleichmäßig verteilten Werten\n",
    "# np.meshgrid liefert Koordinatenmatrizen von Koordinaten Vektoren\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, s),\n",
    "                     np.arange(y_min, y_max, s))\n",
    "# Das Perceptron instanziieren\n",
    "# max_iter = Maximale Anzahl an Iterationen\n",
    "# tol = Stoppkriterium\n",
    "Perceptron = Perceptron(random_state=42,max_iter=1000)\n",
    "# Lernen bitte\n",
    "Perceptron.fit(X,y)\n",
    "# Auswertung für alle Rasterpunkte, dazu wird ein Array Rasterpunkten erzeugt\n",
    "# ravel() erzeugt ein 1-D array\n",
    "# np.c_ erzeugt ein Punktpärchen Arrays für jeden Rasterpunkt, \n",
    "#       die als Input für das Perceptron dienen\n",
    "Prediction = Perceptron.predict(np.c_[xx.ravel(), yy.ravel()])    \n",
    "# Daten anzeigen in einem Plot\n",
    "# Zuerst plotten der Punkthaufen\n",
    "plt.plot(X[:, 0][y == 0], X[:, 1][y == 0], 'b^') # blaue Dreiecke\n",
    "plt.plot(X[:, 0][y == 1], X[:, 1][y == 1], 'ys') # gelbe Quadrate\n",
    "# Umwandlung von 1-D Array in die Rasterdimensionen \n",
    "#                               [x_min, x_max] mal [y_min, y_max]\n",
    "Prediction = Prediction.reshape(xx.shape)\n",
    "# Plotten der Vorhersagen \n",
    "plt.contourf(xx, yy, Prediction, cmap=plt.cm.Paired)\n",
    "# und alles anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 4.11, Listing 4.12, Listing 4.13, Listing 4.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy hilft uns mit den arrays\n",
    "import numpy as np\n",
    "# Grafische Darstellung\n",
    "import matplotlib.pyplot as plt\n",
    "# Das sind unsere Basisklassen\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "# Prüfroutinen \n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\n",
    "# Speichern \n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "# Ganz wichtig, sonst wird der Plot nicht angezeigt\n",
    "%matplotlib inline\n",
    "\n",
    "# Unser Estimator, passend bezeichnet und die Basisklassen\n",
    "class AdalineEstimator(BaseEstimator, ClassifierMixin):\n",
    "    # Initialisierung    \n",
    "    def __init__(self, eta=.001, n_iterations=500, random_state=None):\n",
    "        \"\"\" Initialisierung der Objekte\n",
    "        \n",
    "        eta:          Lernrate\n",
    "        n_iterations: Anzahl der Iterationen für das Lernen\n",
    "        random_state: Um Wiederholbarkeit zu garantieren sollte ein numpy.random.RandomState Objekt \n",
    "                      konstruiert werden, das mit random_state Seed initialisiert wurde \n",
    "                      \n",
    "        \"\"\"\n",
    "        # Die Anzahl der Iterationen   \n",
    "        self.n_iterations = n_iterations\n",
    "        # Die Seed für den Zufallsgenerator\n",
    "        self.random_state = random_state        \n",
    "        # Die Fehler im Lernprozeß für den Plot gepuffert\n",
    "        self.errors = []\n",
    "        # Die Lernrate    \n",
    "        self.eta = eta\n",
    "        # Gewichte für die Berechnung im KNN\n",
    "        self.w = []\n",
    "        # Alle Gewichte für Plot, zum Zeichnen der Trenngeraden     \n",
    "        self.wAll = []\n",
    "        \n",
    "    # Der gewichtete Input       \n",
    "    def net_i(self, x):\n",
    "        \"\"\" Den gewichteten Input w*x berechnen      \n",
    "        x: Ein Vektor          \n",
    "        \"\"\"\n",
    "        return np.dot(x, self.w)\n",
    "    \n",
    "    # Aktivierungsfunktion\n",
    "    def activation(self, x):\n",
    "        \"\"\" Lineare Aktivierungsfunktion      \n",
    "        \"\"\"\n",
    "        return self.net_i(x)\n",
    "    \n",
    "    # Outputfunktion, wobei der Output 1 und -1 sein kann \n",
    "    # im Gegensatz zum Perceptron, wo 1 und 0 ausgegeben werden\n",
    "    def output(self, x):\n",
    "        \"\"\" Outputfunktion      \n",
    "        \"\"\"\n",
    "        if self.activation(x) >= 0.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    # Lernen\n",
    "    def fit(self, X=None, y=None):\n",
    "        \"\"\" Trainieren        \n",
    "        X: Array-ähnliche Struktur mit [N,D], wobei \n",
    "           N = Zeilen = Anzahl der Lernbeispiele und \n",
    "           D = Spalten = Anzahl der Features \n",
    "        y: Array mit [N], mit N so wie oben       \n",
    "        \"\"\" \n",
    "        # Erzeugung des Zufallsgenerators (RNG)\n",
    "        random_state = check_random_state(self.random_state)        \n",
    "        # Gewichtinitialisierung\n",
    "        # np.size(.,1) = Anzahl der Spalten\n",
    "        self.w = random_state.random_sample(np.size(X,1)) \n",
    "        # Prüfe, ob X und y die korrekte Shape haben: X.shape[0] = y.shape[0]\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Lerndaten für spätere Verwendung ablegen\n",
    "        self.X_ = X\n",
    "        self.y_ = y      \n",
    "        # Lernen mit Gradientenabstieg \n",
    "        for i in range(self.n_iterations):\n",
    "            # zufälliges durchwürfeln, für batch size = 1     \n",
    "            # np.size(.,0) = Anzahl der Zeilen\n",
    "            rand_index = random_state.randint(0,np.size(X,0)) \n",
    "            # Ein zufälliger Inputvektor\n",
    "            x_ = X[rand_index]\n",
    "            # Ein dazu passender Output (+1,-1)\n",
    "            y_ = y[rand_index]\n",
    "            # net input s berechnen\n",
    "            s = np.dot(x_, self.w)\n",
    "            # Fehler berechnen als Quadrat der Differenz zwischen \n",
    "            # gewünschem Output und net input\n",
    "            error = (y_ - s)**2\n",
    "            self.errors.append(error)\n",
    "            # Adaline Lernen, so wie beschrieben\n",
    "            self.w += self.eta * x_ * (y_ - s)\n",
    "            # .copy() kopiert die Liste\n",
    "            self.wAll.append(self.w.copy())\n",
    "            \n",
    "    # Auswerten                \n",
    "    def predict(self,x):\n",
    "        \"\"\" Auswerten eines Vektors    \n",
    "        x: Ein Test Inputvektor        \n",
    "        \"\"\"   \n",
    "        # Prüfen, ob fit aufgerufen wurde\n",
    "        # Die Daten wurden in der Methode fit gesetzt\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "        # Auswerten, Forward Path\n",
    "        y_hat = self.output(x)  \n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "    # Plot        \n",
    "    def plot(self):\n",
    "        \"\"\" Ausgabe des Fehlers und der Lernkurve       \n",
    "        Die im Fehlerarray gespeicherten Fehler als Grafik ausgeben\n",
    "        Die Trenngeraden aus den gespeicherten Gewichten ausgeben        \n",
    "        \"\"\"                 \n",
    "        x1 = []\n",
    "        x2 = []\n",
    "        colors = []\n",
    "        \n",
    "        for i in range(self.X_.shape[0]):\n",
    "            x1.append(self.X_[i][1])\n",
    "            x2.append(self.X_[i][2])\n",
    "            y = self.y_[i]\n",
    "            if y == 1:\n",
    "                colors.append('r') # rot\n",
    "            else:\n",
    "                colors.append('b') # blau\n",
    "        # Raster\n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "        # Errors\n",
    "        plt.plot(self.errors)        \n",
    "        # Learning Curve\n",
    "        plt.figure(1)    \n",
    "        plt.show()\n",
    "        # Scatter\n",
    "        plt.figure(2)\n",
    "        plt.scatter(x1, x2,c=colors)  \n",
    "        # Result Line\n",
    "        x1Line = np.linspace(0.0, 1.0, 2)\n",
    "        x2Line = lambda x1, w0, w1, w2: (-x1*w1 - w0) / w2;\n",
    "        alpha = 0.0\n",
    "        for idx, weight in enumerate(self.wAll):\n",
    "            # alpha = Transparenz, je näher zum Ziel desto dunkler\n",
    "            if(idx % 100 == 0):\n",
    "                alpha = 1.0 #( idx / len(self.wAll) )\n",
    "                plt.plot(x1Line, x2Line(x1Line,weight[0],weight[1],weight[2]), alpha=alpha , linestyle='solid', label=str(idx), linewidth=1.5)      \n",
    "        # Ergebnisgerade \n",
    "        plt.plot(x1Line, x2Line(x1Line,weight[0],weight[1],weight[2]), alpha=alpha , linestyle='solid', label=str(idx), linewidth=2.0)  \n",
    "        plt.legend(loc='best', shadow=True)\n",
    "        \n",
    "def main():\n",
    "    # Erzeugung des Zufallsgenerators (RNG)\n",
    "    random_state = check_random_state(1)        \n",
    "    # Initialisierung Datensätze\n",
    "    I = []\n",
    "    o = []\n",
    "    # Datensätze für zwei Kategorien aufbauen \n",
    "    # Diesesmal ohne scikit-learn\n",
    "    for x in random_state.random_sample(20):\n",
    "        y = random_state.random_sample()\n",
    "        I.append([1, x, y+1.0]) # Falls +0.0, dann überlappende Kategorien\n",
    "        o.append(1)\n",
    "\n",
    "    for x in random_state.random_sample(20):\n",
    "        y = random_state.random_sample()\n",
    "        I.append([1, x, y-1.0]) # Falls +0.0, dann überlappende Kategorien\n",
    "        o.append(-1)\n",
    "\n",
    "    # Trainingsdaten\n",
    "    X = np.array(I)\n",
    "    y = np.array(o)\n",
    "    # Walte deines Amtes Estimator\n",
    "    Adaline = AdalineEstimator(eta=0.01,n_iterations=300, random_state=10)\n",
    "    # Lernen\n",
    "    Adaline.fit(X,y)\n",
    "    # Graphen ausgeben\n",
    "    Adaline.plot()\n",
    "    \n",
    "\n",
    "# Hauptprogramm \n",
    "main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(BaseEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(BaseEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
