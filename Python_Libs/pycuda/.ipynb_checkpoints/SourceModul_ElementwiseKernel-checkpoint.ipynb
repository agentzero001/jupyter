{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449331f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.gpuarray as gpuarray\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982a47cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6966533 , -3.7809439 ,  1.3691689 , -1.7882514 ],\n",
       "       [ 1.7559218 , -1.8855509 ,  0.03559884,  0.6662696 ],\n",
       "       [ 2.3568423 , -0.8794475 , -0.8797849 , -1.3574759 ],\n",
       "       [ 0.26086268, -3.4398298 ,  1.7043309 ,  0.57730067]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_gpu = gpuarray.to_gpu(np.random.randn(4,4).astype(np.float32))\n",
    "a_doubled = (2*a_gpu).get()\n",
    "a_doubled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b3c7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code runs at least 3 times faster compared to the hipster garbage you're using\n",
    "mod = SourceModule(\"\"\"\n",
    "__global__ void multiply_them(float *dest, float *a, float *b)\n",
    "{\n",
    "  const int i = threadIdx.x;\n",
    "  dest[i] = a[i] * b[i];\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "multiply_them = mod.get_function(\"multiply_them\")\n",
    "\n",
    "a = np.random.randn(400).astype(np.float32)\n",
    "b = np.random.randn(400).astype(np.float32)\n",
    "\n",
    "dest = np.zeros_like(a)\n",
    "multiply_them(drv.Out(dest), drv.In(a), drv.In(b), block=(400,1,1), grid=(1,1))\n",
    "\n",
    "#dest - (a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa79c317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ker = SourceModule(\"\"\"\n",
    "__global__ void scalar_multiply_kernel(float *outvec, float scalar, float *vec)\n",
    "{\n",
    "    int i = threadIdx.x;\n",
    "    outvec[i] = scalar * vec[i];\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "scalar_multiply_gpu = ker.get_function(\"scalar_multiply_kernel\")\n",
    "\n",
    "testvec = np.random.randn(512).astype(np.float32)\n",
    "testvec_gpu = gpuarray.to_gpu(testvec)\n",
    "outvec_gpu = gpuarray.empty_like(testvec_gpu)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scalar_multiply_gpu(outvec_gpu, np.float32(2), testvec_gpu, block=(512,1,1), grid=(1,1,1))\n",
    "\n",
    "np.allclose(outvec_gpu.get(), testvec*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ecde450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycuda.elementwise import ElementwiseKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84bb2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wtf is a compiler btw?\n",
    "gpu_2x_ker = ElementwiseKernel(\n",
    "\"float *in, float *out\",\n",
    "\"out[i] = 2*in[i];\",\n",
    "\"gpu_2x_kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86119338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_data = np.float32(np.random.random(5_000_000))\n",
    "host_data_2x = 2 * host_data\n",
    "\n",
    "\n",
    "device_data = gpuarray.to_gpu(host_data)\n",
    "device_data_2x = gpuarray.empty_like(device_data)\n",
    "\n",
    "gpu_2x_ker(device_data, device_data_2x)\n",
    "\n",
    "from_device = device_data_2x.get()\n",
    "\n",
    "np.allclose(from_device, host_data_2x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb6db3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c528edfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used for associative binary operations\n",
    "reduce(lambda x, y: x + y, range(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da521b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycuda.scan import InclusiveScanKernel\n",
    "from pycuda.reduction import ReductionKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a3ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = np.array([1, 100, -3, -10000, 4, 10000, 66, 14, 21], dtype=np.int32)\n",
    "seq_gpu = gpuarray.to_gpu(seq)\n",
    "max_gpu = InclusiveScanKernel(np.int32, 'a > b ? a : b')\n",
    "\n",
    "max_gpu(seq_gpu).get()[-1], np.max(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c8c6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,   100,   100,   100,   100, 10000, 10000, 10000, 10000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_gpu(seq_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbecd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_prod = ReductionKernel(np.float32, \n",
    "                           neutral='0',\n",
    "                           reduce_expr='a + b', \n",
    "                           map_expr='vec1[i] * vec2[i]',\n",
    "                           arguments='float *vec1, float *vec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a119e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(14., dtype=float32), 14.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([1,2,3], dtype=np.float32)\n",
    "array_gpu = gpuarray.to_gpu(array)\n",
    "\n",
    "dot_prod(array_gpu, array_gpu), array @ array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc4d95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
