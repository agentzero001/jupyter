{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b9786f",
   "metadata": {},
   "source": [
    "### Turns out this notebook is bullshit for as long as I can not feed a neural network which inherits nn.module with data from my class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b67c886",
   "metadata": {},
   "source": [
    "#### This notebook provides several classes which all inherit torch.utils.data.Dataset and use different means to get your data right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a03a3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c400f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, name, root, filename, transform=None):\n",
    "        self.filename = filename\n",
    "        self.root = root\n",
    "        self.name = name\n",
    "        xy = np.loadtxt('{}/{}'.format(root, filename), delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, 0])\n",
    "        self.n_samples = xy.shape[0]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __repr__(self):\n",
    "        transform_repr = repr(self.transform) if self.transform else 'None'\n",
    "        return (f\"Dataset {self.name}\\n\"\n",
    "                f\"    Number of datapoints: {self.n_samples}\\n\"\n",
    "                f\"    Root location: {self.root}\\n\"\n",
    "                f\"    Filename: {self.filename}\\n\"\n",
    "                f\"    Transform: {transform_repr}\")\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples   \n",
    "    \n",
    "    def train_test_split(self, test_size=.2):\n",
    "        return train_test_split(self.x, self.y, test_size=test_size)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bda6180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,\n",
       " tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
       "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
       "         1.0650e+03]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we create an instance of the class above and look at x_1 and corresponding y_1\n",
    "dataset = CustomDataset(name='wine', root='./data', filename='wine.csv')\n",
    "feature, label = dataset[0]\n",
    "len(dataset), feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b5e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are using the method train_test_split to split or data into a train and test dataset.\n",
    "test_train_data = dataset.train_test_split(test_size=0.1)\n",
    "X_train, X_test, y_train, y_test = test_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838fc702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([160, 13]),\n",
       " torch.Size([160]),\n",
       " torch.Size([18, 13]),\n",
       " torch.Size([18]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115480ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#but we need the data to be inside the class instances so we create our to instances and overwrite the internal data.\n",
    "train_data = CustomDataset(name='wine', root='./data', filename='wine.csv')\n",
    "test_data = CustomDataset(name='wine', root='./data', filename='wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdc05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following chatgpt's suggestion to just overwrite the internal data\n",
    "#scroll down for a better solution\n",
    "train_data.x = X_train; train_data.y = y_train\n",
    "train_data.n_samples = X_train.shape[0]\n",
    "\n",
    "test_data.x = X_test; test_data.y = y_test\n",
    "test_data.n_samples = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "119fa7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset wine\n",
       "    Number of datapoints: 160\n",
       "    Root location: ./data\n",
       "    Filename: wine.csv\n",
       "    Transform: None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107a4848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset wine\n",
       "    Number of datapoints: 18\n",
       "    Root location: ./data\n",
       "    Filename: wine.csv\n",
       "    Transform: None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e06af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the purpose of the class which inherits torch.utils.data.Dataset is that it now is in \n",
    "#the right format to be passed into the torch.utils.data.DataLoader function.\n",
    "#This function will feed data into the neural_networks\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3821f0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.2170e+01, 1.4500e+00, 2.5300e+00, 1.9000e+01, 1.0400e+02, 1.8900e+00,\n",
       "          1.7500e+00, 4.5000e-01, 1.0300e+00, 2.9500e+00, 1.4500e+00, 2.2300e+00,\n",
       "          3.5500e+02],\n",
       "         [1.4390e+01, 1.8700e+00, 2.4500e+00, 1.4600e+01, 9.6000e+01, 2.5000e+00,\n",
       "          2.5200e+00, 3.0000e-01, 1.9800e+00, 5.2500e+00, 1.0200e+00, 3.5800e+00,\n",
       "          1.2900e+03],\n",
       "         [1.3340e+01, 9.4000e-01, 2.3600e+00, 1.7000e+01, 1.1000e+02, 2.5300e+00,\n",
       "          1.3000e+00, 5.5000e-01, 4.2000e-01, 3.1700e+00, 1.0200e+00, 1.9300e+00,\n",
       "          7.5000e+02],\n",
       "         [1.2290e+01, 1.6100e+00, 2.2100e+00, 2.0400e+01, 1.0300e+02, 1.1000e+00,\n",
       "          1.0200e+00, 3.7000e-01, 1.4600e+00, 3.0500e+00, 9.0600e-01, 1.8200e+00,\n",
       "          8.7000e+02]]),\n",
       " tensor([2., 1., 2., 2.])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = next(dataiter)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ae92fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 45, 45)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "total_samples, n_iterations, len(list(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c85db01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2, step 5/45, input.shape = 4\n",
      "1/2, step 10/45, input.shape = 4\n",
      "1/2, step 15/45, input.shape = 4\n",
      "1/2, step 20/45, input.shape = 4\n",
      "1/2, step 25/45, input.shape = 4\n",
      "1/2, step 30/45, input.shape = 4\n",
      "1/2, step 35/45, input.shape = 4\n",
      "1/2, step 40/45, input.shape = 4\n",
      "1/2, step 45/45, input.shape = 2\n",
      "2/2, step 5/45, input.shape = 4\n",
      "2/2, step 10/45, input.shape = 4\n",
      "2/2, step 15/45, input.shape = 4\n",
      "2/2, step 20/45, input.shape = 4\n",
      "2/2, step 25/45, input.shape = 4\n",
      "2/2, step 30/45, input.shape = 4\n",
      "2/2, step 35/45, input.shape = 4\n",
      "2/2, step 40/45, input.shape = 4\n",
      "2/2, step 45/45, input.shape = 2\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        if (i+1) % 5 == 0:\n",
    "            print('{}/{}, step {}/{}, input.shape = {}'.format(epoch+1, num_epochs, i+1,\n",
    "                                                               n_iterations, inputs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29979b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d801a895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:02<00:00, 3722962.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data\\MNIST\\raw\\train-images-idx3-ubyte.gz to /data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 290734.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to /data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 2286090.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to /data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 4540164.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to /data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root='/data', train=True, download=True,\n",
    "                               transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ea506a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35e58e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset wine\n",
       "    Number of datapoints: 178\n",
       "    Root location: ./data\n",
       "    Filename: wine.csv\n",
       "    Transform: None"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52e594ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "687fd753",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader2 = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30250d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f865fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset where numpy is used to read a csv file, where the first row are the labels and the first column \n",
    "#is goint go be y. It should be easy to change your y or scroll down for a class which gets a pandas df as input\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, name, root, filename, train, transform=None, test_size=.2):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        self.filename = filename\n",
    "        self.root = root\n",
    "        self.name = name\n",
    "        xy = np.loadtxt('{}/{}'.format(root, filename), delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.xtemp = torch.from_numpy(xy[:, 1:])\n",
    "        self.ytemp = torch.from_numpy(xy[:, 0])\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.test_size = test_size\n",
    "        self.x, self.y = self.split()\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        \n",
    "    def split(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.xtemp,\n",
    "                                                            self.ytemp, \n",
    "                                                            test_size=self.test_size,\n",
    "                                                            random_state=42)\n",
    "        if self.train:\n",
    "            return X_train, y_train\n",
    "        else:\n",
    "            return X_test, y_test\n",
    "    \n",
    "    def __repr__(self):\n",
    "        transform_repr = repr(self.transform) if self.transform else 'None'\n",
    "        return (f\"Dataset {self.name}\\n\"\n",
    "                f\"    Number of datapoints: {self.n_samples}\\n\"\n",
    "                f\"    Root location: {self.root}\\n\"\n",
    "                f\"    Filename: {self.filename}\\n\"\n",
    "                f\"    Transform: {transform_repr}\")\n",
    "\n",
    "    #this should do\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cd85690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the random_state parameter will ensure that the same split is happening for both class instances. Right?\n",
    "train_dataset = CustomDataset(name='wine', root='./data', filename='wine.csv', train=True, test_size=.1)\n",
    "test_dataset = CustomDataset(name='wine', root='./data', filename='wine.csv', train=False, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bac6a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset wine\n",
       "    Number of datapoints: 160\n",
       "    Root location: ./data\n",
       "    Filename: wine.csv\n",
       "    Transform: None"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88a843b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.3860e+01, 1.3500e+00, 2.2700e+00, 1.6000e+01, 9.8000e+01, 2.9800e+00,\n",
       "         3.1500e+00, 2.2000e-01, 1.8500e+00, 7.2200e+00, 1.0100e+00, 3.5500e+00,\n",
       "         1.0450e+03]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34ab5f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset wine\n",
       "    Number of datapoints: 18\n",
       "    Root location: ./data\n",
       "    Filename: wine.csv\n",
       "    Transform: None"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bb41e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader3 = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ba42e347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4, step 5/45, input.shape = 4\n",
      "1/4, step 10/45, input.shape = 4\n",
      "1/4, step 15/45, input.shape = 4\n",
      "1/4, step 20/45, input.shape = 4\n",
      "1/4, step 25/45, input.shape = 4\n",
      "1/4, step 30/45, input.shape = 4\n",
      "1/4, step 35/45, input.shape = 4\n",
      "1/4, step 40/45, input.shape = 4\n",
      "2/4, step 5/45, input.shape = 4\n",
      "2/4, step 10/45, input.shape = 4\n",
      "2/4, step 15/45, input.shape = 4\n",
      "2/4, step 20/45, input.shape = 4\n",
      "2/4, step 25/45, input.shape = 4\n",
      "2/4, step 30/45, input.shape = 4\n",
      "2/4, step 35/45, input.shape = 4\n",
      "2/4, step 40/45, input.shape = 4\n",
      "3/4, step 5/45, input.shape = 4\n",
      "3/4, step 10/45, input.shape = 4\n",
      "3/4, step 15/45, input.shape = 4\n",
      "3/4, step 20/45, input.shape = 4\n",
      "3/4, step 25/45, input.shape = 4\n",
      "3/4, step 30/45, input.shape = 4\n",
      "3/4, step 35/45, input.shape = 4\n",
      "3/4, step 40/45, input.shape = 4\n",
      "4/4, step 5/45, input.shape = 4\n",
      "4/4, step 10/45, input.shape = 4\n",
      "4/4, step 15/45, input.shape = 4\n",
      "4/4, step 20/45, input.shape = 4\n",
      "4/4, step 25/45, input.shape = 4\n",
      "4/4, step 30/45, input.shape = 4\n",
      "4/4, step 35/45, input.shape = 4\n",
      "4/4, step 40/45, input.shape = 4\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader3):\n",
    "        if (i+1) % 5 == 0:\n",
    "            print('{}/{}, step {}/{}, input.shape = {}'.format(epoch+1,\n",
    "                                                               num_epochs,\n",
    "                                                               i+1,\n",
    "                                                               n_iterations,\n",
    "                                                               inputs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c00938ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need a transform function, because tansforming your data is a good and important practice.\n",
    "normalize = lambda X: (X - X.mean(0)) / X.std(0)\n",
    "normalize.__name__ = 'normalize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4ff05326",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CustomDataset.__init__() got an unexpected keyword argument 'root'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwine\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                              root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                              filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwine.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      4\u001b[0m                              train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.1\u001b[39m,\n\u001b[0;32m      5\u001b[0m                              transform\u001b[38;5;241m=\u001b[39mnormalize)\n",
      "\u001b[1;31mTypeError\u001b[0m: CustomDataset.__init__() got an unexpected keyword argument 'root'"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset(name='wine',\n",
    "                             root='./data',\n",
    "                             filename='wine.csv', \n",
    "                             train=False, test_size=.1,\n",
    "                             transform=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "afe03850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset wine\n",
       "    Number of datapoints: 490\n",
       "    Transform: None"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f63568f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21) tensor(45.1615, dtype=torch.float64)\n",
      "tensor(17) tensor(38.1102, dtype=torch.float64)\n",
      "tensor(16) tensor(36.7707, dtype=torch.float64)\n",
      "tensor(18) tensor(43.8934, dtype=torch.float64)\n",
      "tensor(13) tensor(26.9366, dtype=torch.float64)\n",
      "tensor(25) tensor(59.2992, dtype=torch.float64)\n",
      "tensor(26) tensor(67.4797, dtype=torch.float64)\n",
      "tensor(12) tensor(31.2259, dtype=torch.float64)\n",
      "tensor(9) tensor(17.0197, dtype=torch.float64)\n",
      "tensor(23) tensor(56.2457, dtype=torch.float64)\n",
      "tensor(19) tensor(42.2210, dtype=torch.float64)\n",
      "tensor(13) tensor(30.8478, dtype=torch.float64)\n",
      "tensor(19) tensor(44.0206, dtype=torch.float64)\n",
      "tensor(14) tensor(34.2249, dtype=torch.float64)\n",
      "tensor(20) tensor(37.5324, dtype=torch.float64)\n",
      "tensor(25) tensor(58.5874, dtype=torch.float64)\n",
      "tensor(20) tensor(43.0752, dtype=torch.float64)\n",
      "tensor(15) tensor(38.7683, dtype=torch.float64)\n",
      "tensor(20) tensor(49.6903, dtype=torch.float64)\n",
      "tensor(14) tensor(29.5986, dtype=torch.float64)\n",
      "tensor(18) tensor(39.6567, dtype=torch.float64)\n",
      "tensor(13) tensor(31.2405, dtype=torch.float64)\n",
      "tensor(22) tensor(49.9622, dtype=torch.float64)\n",
      "tensor(17) tensor(37.6475, dtype=torch.float64)\n",
      "tensor(16) tensor(33.9906, dtype=torch.float64)\n",
      "tensor(18) tensor(43.0938, dtype=torch.float64)\n",
      "tensor(19) tensor(44.7545, dtype=torch.float64)\n",
      "tensor(16) tensor(35.7884, dtype=torch.float64)\n",
      "tensor(21) tensor(49.8897, dtype=torch.float64)\n",
      "tensor(18) tensor(44.5068, dtype=torch.float64)\n",
      "tensor(26) tensor(63.9605, dtype=torch.float64)\n",
      "tensor(23) tensor(51.9625, dtype=torch.float64)\n",
      "tensor(33) tensor(81.3381, dtype=torch.float64)\n",
      "tensor(18) tensor(44.1682, dtype=torch.float64)\n",
      "tensor(24) tensor(54.8103, dtype=torch.float64)\n",
      "tensor(17) tensor(37.1972, dtype=torch.float64)\n",
      "tensor(9) tensor(19.0203, dtype=torch.float64)\n",
      "tensor(27) tensor(67.2171, dtype=torch.float64)\n",
      "tensor(18) tensor(42.6027, dtype=torch.float64)\n",
      "tensor(14) tensor(31.4603, dtype=torch.float64)\n",
      "tensor(18) tensor(41.6661, dtype=torch.float64)\n",
      "tensor(25) tensor(56.4059, dtype=torch.float64)\n",
      "tensor(16) tensor(36.5083, dtype=torch.float64)\n",
      "tensor(9) tensor(20.3756, dtype=torch.float64)\n",
      "tensor(14) tensor(34.3510, dtype=torch.float64)\n",
      "tensor(25) tensor(65.1271, dtype=torch.float64)\n",
      "tensor(16) tensor(36.1350, dtype=torch.float64)\n",
      "tensor(27) tensor(66.5903, dtype=torch.float64)\n",
      "tensor(23) tensor(54.2942, dtype=torch.float64)\n",
      "tensor(28) tensor(63.2257, dtype=torch.float64)\n",
      "tensor(15) tensor(40.7761, dtype=torch.float64)\n",
      "tensor(25) tensor(55.7271, dtype=torch.float64)\n",
      "tensor(14) tensor(35.8943, dtype=torch.float64)\n",
      "tensor(12) tensor(24.6403, dtype=torch.float64)\n",
      "tensor(18) tensor(42.0003, dtype=torch.float64)\n",
      "tensor(15) tensor(35.9953, dtype=torch.float64)\n",
      "tensor(24) tensor(59.5397, dtype=torch.float64)\n",
      "tensor(9) tensor(18.2628, dtype=torch.float64)\n",
      "tensor(13) tensor(30.5802, dtype=torch.float64)\n",
      "tensor(25) tensor(57.1470, dtype=torch.float64)\n",
      "tensor(19) tensor(44.9922, dtype=torch.float64)\n",
      "tensor(25) tensor(56.8363, dtype=torch.float64)\n",
      "tensor(15) tensor(38.9516, dtype=torch.float64)\n",
      "tensor(20) tensor(41.7872, dtype=torch.float64)\n",
      "tensor(22) tensor(48.8774, dtype=torch.float64)\n",
      "tensor(15) tensor(32.5463, dtype=torch.float64)\n",
      "tensor(16) tensor(35.5649, dtype=torch.float64)\n",
      "tensor(28) tensor(67.6449, dtype=torch.float64)\n",
      "tensor(14) tensor(32.5189, dtype=torch.float64)\n",
      "tensor(17) tensor(39.6545, dtype=torch.float64)\n",
      "tensor(21) tensor(49.8637, dtype=torch.float64)\n",
      "tensor(15) tensor(31.7732, dtype=torch.float64)\n",
      "tensor(12) tensor(25.8248, dtype=torch.float64)\n",
      "tensor(19) tensor(49.7314, dtype=torch.float64)\n",
      "tensor(26) tensor(59.4070, dtype=torch.float64)\n",
      "tensor(18) tensor(35.9478, dtype=torch.float64)\n",
      "tensor(14) tensor(32.2349, dtype=torch.float64)\n",
      "tensor(17) tensor(39.8317, dtype=torch.float64)\n",
      "tensor(23) tensor(52.1534, dtype=torch.float64)\n",
      "tensor(17) tensor(38.8150, dtype=torch.float64)\n",
      "tensor(14) tensor(29.9335, dtype=torch.float64)\n",
      "tensor(16) tensor(42.2470, dtype=torch.float64)\n",
      "tensor(15) tensor(34.9391, dtype=torch.float64)\n",
      "tensor(20) tensor(48.3880, dtype=torch.float64)\n",
      "tensor(13) tensor(30.7487, dtype=torch.float64)\n",
      "tensor(16) tensor(34.6066, dtype=torch.float64)\n",
      "tensor(23) tensor(54.0070, dtype=torch.float64)\n",
      "tensor(17) tensor(41.9922, dtype=torch.float64)\n",
      "tensor(17) tensor(36.5016, dtype=torch.float64)\n",
      "tensor(27) tensor(62.7598, dtype=torch.float64)\n",
      "tensor(18) tensor(42.1851, dtype=torch.float64)\n",
      "tensor(25) tensor(62.9613, dtype=torch.float64)\n",
      "tensor(22) tensor(52.0962, dtype=torch.float64)\n",
      "tensor(12) tensor(28.0202, dtype=torch.float64)\n",
      "tensor(13) tensor(28.8978, dtype=torch.float64)\n",
      "tensor(22) tensor(49.7483, dtype=torch.float64)\n",
      "tensor(10) tensor(18.2934, dtype=torch.float64)\n",
      "tensor(19) tensor(39.1202, dtype=torch.float64)\n",
      "tensor(21) tensor(47.7404, dtype=torch.float64)\n",
      "tensor(17) tensor(36.1412, dtype=torch.float64)\n",
      "tensor(24) tensor(57.4166, dtype=torch.float64)\n",
      "tensor(11) tensor(27.0028, dtype=torch.float64)\n",
      "tensor(19) tensor(41.9393, dtype=torch.float64)\n",
      "tensor(17) tensor(38.3398, dtype=torch.float64)\n",
      "tensor(15) tensor(35.3350, dtype=torch.float64)\n",
      "tensor(20) tensor(40.4900, dtype=torch.float64)\n",
      "tensor(25) tensor(57.1470, dtype=torch.float64)\n",
      "tensor(15) tensor(33.8129, dtype=torch.float64)\n",
      "tensor(15) tensor(38.7683, dtype=torch.float64)\n",
      "tensor(15) tensor(34.1264, dtype=torch.float64)\n",
      "tensor(12) tensor(25.5697, dtype=torch.float64)\n",
      "tensor(13) tensor(27.8776, dtype=torch.float64)\n",
      "tensor(14) tensor(28.4299, dtype=torch.float64)\n",
      "tensor(25) tensor(57.2851, dtype=torch.float64)\n",
      "tensor(21) tensor(46.0294, dtype=torch.float64)\n",
      "tensor(16) tensor(36.7549, dtype=torch.float64)\n",
      "tensor(13) tensor(26.1657, dtype=torch.float64)\n",
      "tensor(12) tensor(25.8136, dtype=torch.float64)\n",
      "tensor(24) tensor(55.5778, dtype=torch.float64)\n",
      "tensor(21) tensor(46.2268, dtype=torch.float64)\n",
      "tensor(23) tensor(59.3273, dtype=torch.float64)\n",
      "tensor(19) tensor(41.0148, dtype=torch.float64)\n",
      "tensor(16) tensor(35.5770, dtype=torch.float64)\n",
      "tensor(23) tensor(56.8488, dtype=torch.float64)\n",
      "tensor(20) tensor(44.9804, dtype=torch.float64)\n",
      "tensor(11) tensor(22.5801, dtype=torch.float64)\n",
      "tensor(10) tensor(19.9329, dtype=torch.float64)\n",
      "tensor(19) tensor(46.4654, dtype=torch.float64)\n",
      "tensor(14) tensor(30.6505, dtype=torch.float64)\n",
      "tensor(26) tensor(62.2119, dtype=torch.float64)\n",
      "tensor(13) tensor(33.2483, dtype=torch.float64)\n",
      "tensor(25) tensor(52.1862, dtype=torch.float64)\n",
      "tensor(28) tensor(69.4996, dtype=torch.float64)\n",
      "tensor(13) tensor(31.1165, dtype=torch.float64)\n",
      "tensor(15) tensor(40.0699, dtype=torch.float64)\n",
      "tensor(25) tensor(52.9330, dtype=torch.float64)\n",
      "tensor(17) tensor(33.9754, dtype=torch.float64)\n",
      "tensor(26) tensor(63.8953, dtype=torch.float64)\n",
      "tensor(22) tensor(57.0962, dtype=torch.float64)\n",
      "tensor(23) tensor(50.7882, dtype=torch.float64)\n",
      "tensor(15) tensor(36.9154, dtype=torch.float64)\n",
      "tensor(18) tensor(38.5890, dtype=torch.float64)\n",
      "tensor(19) tensor(48.2776, dtype=torch.float64)\n",
      "tensor(22) tensor(52.3743, dtype=torch.float64)\n",
      "tensor(17) tensor(36.9185, dtype=torch.float64)\n",
      "tensor(24) tensor(55.3379, dtype=torch.float64)\n",
      "tensor(19) tensor(44.7837, dtype=torch.float64)\n",
      "tensor(14) tensor(33.1318, dtype=torch.float64)\n",
      "tensor(28) tensor(67.3828, dtype=torch.float64)\n",
      "tensor(20) tensor(46.2204, dtype=torch.float64)\n",
      "tensor(18) tensor(42.5342, dtype=torch.float64)\n",
      "tensor(13) tensor(29.4340, dtype=torch.float64)\n",
      "tensor(11) tensor(23.1089, dtype=torch.float64)\n",
      "tensor(20) tensor(45.6816, dtype=torch.float64)\n",
      "tensor(13) tensor(27.2257, dtype=torch.float64)\n",
      "tensor(10) tensor(24.6160, dtype=torch.float64)\n",
      "tensor(16) tensor(36.3727, dtype=torch.float64)\n",
      "tensor(14) tensor(27.9582, dtype=torch.float64)\n",
      "tensor(12) tensor(26.8181, dtype=torch.float64)\n",
      "tensor(23) tensor(52.8942, dtype=torch.float64)\n",
      "tensor(31) tensor(72.6910, dtype=torch.float64)\n",
      "tensor(25) tensor(60.1372, dtype=torch.float64)\n",
      "tensor(19) tensor(38.9354, dtype=torch.float64)\n",
      "tensor(26) tensor(60.4454, dtype=torch.float64)\n",
      "tensor(21) tensor(45.1608, dtype=torch.float64)\n",
      "tensor(14) tensor(27.3650, dtype=torch.float64)\n",
      "tensor(15) tensor(35.6743, dtype=torch.float64)\n",
      "tensor(10) tensor(22.0084, dtype=torch.float64)\n",
      "tensor(26) tensor(59.3407, dtype=torch.float64)\n",
      "tensor(18) tensor(40.6135, dtype=torch.float64)\n",
      "tensor(15) tensor(37.1318, dtype=torch.float64)\n",
      "tensor(11) tensor(23.5094, dtype=torch.float64)\n",
      "tensor(12) tensor(26.1679, dtype=torch.float64)\n",
      "tensor(14) tensor(33.7902, dtype=torch.float64)\n",
      "tensor(15) tensor(31.5461, dtype=torch.float64)\n",
      "tensor(16) tensor(38.9514, dtype=torch.float64)\n",
      "tensor(29) tensor(70.8173, dtype=torch.float64)\n",
      "tensor(20) tensor(44.6610, dtype=torch.float64)\n",
      "tensor(14) tensor(32.1105, dtype=torch.float64)\n",
      "tensor(14) tensor(33.3649, dtype=torch.float64)\n",
      "tensor(21) tensor(43.2435, dtype=torch.float64)\n",
      "tensor(12) tensor(28.4872, dtype=torch.float64)\n",
      "tensor(14) tensor(32.9656, dtype=torch.float64)\n",
      "tensor(13) tensor(29.2634, dtype=torch.float64)\n",
      "tensor(17) tensor(34.8518, dtype=torch.float64)\n",
      "tensor(18) tensor(44.7200, dtype=torch.float64)\n",
      "tensor(12) tensor(23.9668, dtype=torch.float64)\n",
      "tensor(20) tensor(46.6071, dtype=torch.float64)\n",
      "tensor(28) tensor(74.9482, dtype=torch.float64)\n",
      "tensor(38) tensor(102.4739, dtype=torch.float64)\n",
      "tensor(23) tensor(49.4541, dtype=torch.float64)\n",
      "tensor(11) tensor(24.4819, dtype=torch.float64)\n",
      "tensor(19) tensor(43.9028, dtype=torch.float64)\n",
      "tensor(15) tensor(30.6363, dtype=torch.float64)\n",
      "tensor(29) tensor(72.8264, dtype=torch.float64)\n",
      "tensor(28) tensor(65.1830, dtype=torch.float64)\n",
      "tensor(14) tensor(28.2633, dtype=torch.float64)\n",
      "tensor(13) tensor(26.3444, dtype=torch.float64)\n",
      "tensor(14) tensor(34.1935, dtype=torch.float64)\n",
      "tensor(18) tensor(48.5139, dtype=torch.float64)\n",
      "tensor(17) tensor(38.3034, dtype=torch.float64)\n",
      "tensor(18) tensor(41.7996, dtype=torch.float64)\n",
      "tensor(14) tensor(31.7811, dtype=torch.float64)\n",
      "tensor(18) tensor(38.5513, dtype=torch.float64)\n",
      "tensor(11) tensor(26.0836, dtype=torch.float64)\n",
      "tensor(15) tensor(36.4066, dtype=torch.float64)\n",
      "tensor(13) tensor(31.3492, dtype=torch.float64)\n",
      "tensor(15) tensor(32.9016, dtype=torch.float64)\n",
      "tensor(30) tensor(65.5597, dtype=torch.float64)\n",
      "tensor(17) tensor(45.7652, dtype=torch.float64)\n",
      "tensor(23) tensor(54.1956, dtype=torch.float64)\n",
      "tensor(11) tensor(21.1836, dtype=torch.float64)\n",
      "tensor(17) tensor(35.2122, dtype=torch.float64)\n",
      "tensor(16) tensor(36.6736, dtype=torch.float64)\n",
      "tensor(17) tensor(43.1402, dtype=torch.float64)\n",
      "tensor(11) tensor(26.2094, dtype=torch.float64)\n",
      "tensor(15) tensor(38.4860, dtype=torch.float64)\n",
      "tensor(22) tensor(48.4449, dtype=torch.float64)\n",
      "tensor(25) tensor(56.8363, dtype=torch.float64)\n",
      "tensor(12) tensor(27.4861, dtype=torch.float64)\n",
      "tensor(19) tensor(39.7679, dtype=torch.float64)\n",
      "tensor(23) tensor(50.1213, dtype=torch.float64)\n",
      "tensor(22) tensor(54.2742, dtype=torch.float64)\n",
      "tensor(16) tensor(35.7538, dtype=torch.float64)\n",
      "tensor(10) tensor(20.3928, dtype=torch.float64)\n",
      "tensor(12) tensor(26.5628, dtype=torch.float64)\n",
      "tensor(21) tensor(53.2997, dtype=torch.float64)\n",
      "tensor(14) tensor(30.3753, dtype=torch.float64)\n",
      "tensor(13) tensor(29.4179, dtype=torch.float64)\n",
      "tensor(30) tensor(71.9108, dtype=torch.float64)\n",
      "tensor(17) tensor(40.0870, dtype=torch.float64)\n",
      "tensor(23) tensor(54.9145, dtype=torch.float64)\n",
      "tensor(16) tensor(33.8308, dtype=torch.float64)\n",
      "tensor(20) tensor(49.8640, dtype=torch.float64)\n",
      "tensor(23) tensor(49.5998, dtype=torch.float64)\n",
      "tensor(15) tensor(36.1933, dtype=torch.float64)\n",
      "tensor(20) tensor(51.0125, dtype=torch.float64)\n",
      "tensor(21) tensor(48.9297, dtype=torch.float64)\n",
      "tensor(20) tensor(41.4951, dtype=torch.float64)\n",
      "tensor(22) tensor(49.7639, dtype=torch.float64)\n",
      "tensor(15) tensor(36.5264, dtype=torch.float64)\n",
      "tensor(8) tensor(14.8317, dtype=torch.float64)\n",
      "tensor(15) tensor(34.8701, dtype=torch.float64)\n",
      "tensor(16) tensor(37.8866, dtype=torch.float64)\n",
      "tensor(10) tensor(22.2801, dtype=torch.float64)\n",
      "tensor(8) tensor(19.0249, dtype=torch.float64)\n",
      "tensor(7) tensor(16.1258, dtype=torch.float64)\n",
      "tensor(12) tensor(27.3837, dtype=torch.float64)\n",
      "tensor(10) tensor(24.0173, dtype=torch.float64)\n",
      "tensor(21) tensor(54.2585, dtype=torch.float64)\n",
      "tensor(25) tensor(54.5305, dtype=torch.float64)\n",
      "tensor(12) tensor(29.8765, dtype=torch.float64)\n",
      "tensor(22) tensor(56.6722, dtype=torch.float64)\n",
      "tensor(15) tensor(40.4669, dtype=torch.float64)\n",
      "tensor(12) tensor(27.7804, dtype=torch.float64)\n",
      "tensor(21) tensor(49.8950, dtype=torch.float64)\n",
      "tensor(15) tensor(32.7827, dtype=torch.float64)\n",
      "tensor(22) tensor(51.3916, dtype=torch.float64)\n",
      "tensor(11) tensor(23.6328, dtype=torch.float64)\n",
      "tensor(16) tensor(38.7465, dtype=torch.float64)\n",
      "tensor(22) tensor(48.1421, dtype=torch.float64)\n",
      "tensor(28) tensor(67.0449, dtype=torch.float64)\n",
      "tensor(12) tensor(29.0600, dtype=torch.float64)\n",
      "tensor(19) tensor(48.8181, dtype=torch.float64)\n",
      "tensor(20) tensor(51.3506, dtype=torch.float64)\n",
      "tensor(13) tensor(25.5947, dtype=torch.float64)\n",
      "tensor(25) tensor(57.3187, dtype=torch.float64)\n",
      "tensor(14) tensor(27.6551, dtype=torch.float64)\n",
      "tensor(16) tensor(37.2782, dtype=torch.float64)\n",
      "tensor(13) tensor(29.7214, dtype=torch.float64)\n",
      "tensor(30) tensor(65.5086, dtype=torch.float64)\n",
      "tensor(23) tensor(53.8412, dtype=torch.float64)\n",
      "tensor(26) tensor(58.2195, dtype=torch.float64)\n",
      "tensor(14) tensor(27.8744, dtype=torch.float64)\n",
      "tensor(22) tensor(47.1498, dtype=torch.float64)\n",
      "tensor(23) tensor(49.4589, dtype=torch.float64)\n",
      "tensor(8) tensor(19.3399, dtype=torch.float64)\n",
      "tensor(18) tensor(43.4785, dtype=torch.float64)\n",
      "tensor(20) tensor(41.7166, dtype=torch.float64)\n",
      "tensor(34) tensor(83.6332, dtype=torch.float64)\n",
      "tensor(10) tensor(21.3077, dtype=torch.float64)\n",
      "tensor(26) tensor(59.4070, dtype=torch.float64)\n",
      "tensor(10) tensor(21.6351, dtype=torch.float64)\n",
      "tensor(13) tensor(33.5887, dtype=torch.float64)\n",
      "tensor(21) tensor(50.6562, dtype=torch.float64)\n",
      "tensor(16) tensor(34.2363, dtype=torch.float64)\n",
      "tensor(23) tensor(49.5122, dtype=torch.float64)\n",
      "tensor(19) tensor(47.1021, dtype=torch.float64)\n",
      "tensor(25) tensor(56.6411, dtype=torch.float64)\n",
      "tensor(14) tensor(33.7764, dtype=torch.float64)\n",
      "tensor(12) tensor(27.2945, dtype=torch.float64)\n",
      "tensor(14) tensor(34.3938, dtype=torch.float64)\n",
      "tensor(13) tensor(27.8977, dtype=torch.float64)\n",
      "tensor(16) tensor(38.5448, dtype=torch.float64)\n",
      "tensor(21) tensor(52.4214, dtype=torch.float64)\n",
      "tensor(16) tensor(36.8508, dtype=torch.float64)\n",
      "tensor(7) tensor(11.9971, dtype=torch.float64)\n",
      "tensor(23) tensor(56.5370, dtype=torch.float64)\n",
      "tensor(33) tensor(78.8194, dtype=torch.float64)\n",
      "tensor(14) tensor(30.7457, dtype=torch.float64)\n",
      "tensor(15) tensor(40.7761, dtype=torch.float64)\n",
      "tensor(24) tensor(53.4242, dtype=torch.float64)\n",
      "tensor(20) tensor(46.1815, dtype=torch.float64)\n",
      "tensor(12) tensor(28.7415, dtype=torch.float64)\n",
      "tensor(14) tensor(32.9891, dtype=torch.float64)\n",
      "tensor(20) tensor(49.0078, dtype=torch.float64)\n",
      "tensor(22) tensor(50.5367, dtype=torch.float64)\n",
      "tensor(13) tensor(28.8597, dtype=torch.float64)\n",
      "tensor(10) tensor(22.3711, dtype=torch.float64)\n",
      "tensor(10) tensor(24.9439, dtype=torch.float64)\n",
      "tensor(14) tensor(31.9100, dtype=torch.float64)\n",
      "tensor(23) tensor(57.5412, dtype=torch.float64)\n",
      "tensor(22) tensor(55.5997, dtype=torch.float64)\n",
      "tensor(23) tensor(50.8430, dtype=torch.float64)\n",
      "tensor(9) tensor(20.0651, dtype=torch.float64)\n",
      "tensor(13) tensor(25.9974, dtype=torch.float64)\n",
      "tensor(16) tensor(36.1815, dtype=torch.float64)\n",
      "tensor(15) tensor(35.5097, dtype=torch.float64)\n",
      "tensor(18) tensor(50.6606, dtype=torch.float64)\n",
      "tensor(16) tensor(35.0096, dtype=torch.float64)\n",
      "tensor(15) tensor(33.4916, dtype=torch.float64)\n",
      "tensor(19) tensor(38.8619, dtype=torch.float64)\n",
      "tensor(15) tensor(33.9306, dtype=torch.float64)\n",
      "tensor(12) tensor(24.5249, dtype=torch.float64)\n",
      "tensor(5) tensor(8.5246, dtype=torch.float64)\n",
      "tensor(13) tensor(29.8695, dtype=torch.float64)\n",
      "tensor(18) tensor(38.1000, dtype=torch.float64)\n",
      "tensor(23) tensor(51.2678, dtype=torch.float64)\n",
      "tensor(15) tensor(34.9857, dtype=torch.float64)\n",
      "tensor(20) tensor(43.3868, dtype=torch.float64)\n",
      "tensor(20) tensor(48.8972, dtype=torch.float64)\n",
      "tensor(12) tensor(24.7762, dtype=torch.float64)\n",
      "tensor(20) tensor(39.6754, dtype=torch.float64)\n",
      "tensor(22) tensor(48.8319, dtype=torch.float64)\n",
      "tensor(15) tensor(36.2612, dtype=torch.float64)\n",
      "tensor(9) tensor(19.8991, dtype=torch.float64)\n",
      "tensor(19) tensor(41.2218, dtype=torch.float64)\n",
      "tensor(17) tensor(37.7805, dtype=torch.float64)\n",
      "tensor(11) tensor(24.1938, dtype=torch.float64)\n",
      "tensor(17) tensor(37.3669, dtype=torch.float64)\n",
      "tensor(14) tensor(35.9295, dtype=torch.float64)\n",
      "tensor(19) tensor(44.0514, dtype=torch.float64)\n",
      "tensor(15) tensor(32.5097, dtype=torch.float64)\n",
      "tensor(31) tensor(71.0676, dtype=torch.float64)\n",
      "tensor(19) tensor(46.5621, dtype=torch.float64)\n",
      "tensor(16) tensor(38.0994, dtype=torch.float64)\n",
      "tensor(21) tensor(55.9497, dtype=torch.float64)\n",
      "tensor(21) tensor(58.0936, dtype=torch.float64)\n",
      "tensor(19) tensor(43.8784, dtype=torch.float64)\n",
      "tensor(20) tensor(41.9695, dtype=torch.float64)\n",
      "tensor(19) tensor(44.0706, dtype=torch.float64)\n",
      "tensor(16) tensor(32.3119, dtype=torch.float64)\n",
      "tensor(15) tensor(35.3350, dtype=torch.float64)\n",
      "tensor(24) tensor(52.1751, dtype=torch.float64)\n",
      "tensor(16) tensor(36.5723, dtype=torch.float64)\n",
      "tensor(15) tensor(40.4669, dtype=torch.float64)\n",
      "tensor(15) tensor(35.1505, dtype=torch.float64)\n",
      "tensor(13) tensor(28.1006, dtype=torch.float64)\n",
      "tensor(14) tensor(32.4523, dtype=torch.float64)\n",
      "tensor(23) tensor(51.9910, dtype=torch.float64)\n",
      "tensor(26) tensor(65.4767, dtype=torch.float64)\n",
      "tensor(22) tensor(52.1005, dtype=torch.float64)\n",
      "tensor(18) tensor(45.1813, dtype=torch.float64)\n",
      "tensor(20) tensor(42.6008, dtype=torch.float64)\n",
      "tensor(10) tensor(19.7392, dtype=torch.float64)\n",
      "tensor(28) tensor(72.7912, dtype=torch.float64)\n",
      "tensor(29) tensor(74.5137, dtype=torch.float64)\n",
      "tensor(22) tensor(53.9545, dtype=torch.float64)\n",
      "tensor(18) tensor(41.5738, dtype=torch.float64)\n",
      "tensor(24) tensor(58.0301, dtype=torch.float64)\n",
      "tensor(19) tensor(44.2546, dtype=torch.float64)\n",
      "tensor(21) tensor(49.4900, dtype=torch.float64)\n",
      "tensor(21) tensor(49.8941, dtype=torch.float64)\n",
      "tensor(15) tensor(33.3683, dtype=torch.float64)\n",
      "tensor(18) tensor(41.6451, dtype=torch.float64)\n",
      "tensor(26) tensor(65.4549, dtype=torch.float64)\n",
      "tensor(11) tensor(27.9046, dtype=torch.float64)\n",
      "tensor(25) tensor(54.1704, dtype=torch.float64)\n",
      "tensor(20) tensor(50.3546, dtype=torch.float64)\n",
      "tensor(26) tensor(66.4631, dtype=torch.float64)\n",
      "tensor(13) tensor(27.2233, dtype=torch.float64)\n",
      "tensor(20) tensor(48.7078, dtype=torch.float64)\n",
      "tensor(21) tensor(46.0145, dtype=torch.float64)\n",
      "tensor(8) tensor(16.1482, dtype=torch.float64)\n",
      "tensor(20) tensor(42.2491, dtype=torch.float64)\n",
      "tensor(21) tensor(54.6850, dtype=torch.float64)\n",
      "tensor(20) tensor(45.0810, dtype=torch.float64)\n",
      "tensor(13) tensor(26.2176, dtype=torch.float64)\n",
      "tensor(23) tensor(49.5587, dtype=torch.float64)\n",
      "tensor(22) tensor(49.1547, dtype=torch.float64)\n",
      "tensor(24) tensor(58.8468, dtype=torch.float64)\n",
      "tensor(10) tensor(21.3994, dtype=torch.float64)\n",
      "tensor(22) tensor(46.5184, dtype=torch.float64)\n",
      "tensor(22) tensor(48.6000, dtype=torch.float64)\n",
      "tensor(22) tensor(57.6558, dtype=torch.float64)\n",
      "tensor(29) tensor(67.3773, dtype=torch.float64)\n",
      "tensor(9) tensor(17.3813, dtype=torch.float64)\n",
      "tensor(22) tensor(51.8436, dtype=torch.float64)\n",
      "tensor(14) tensor(29.3989, dtype=torch.float64)\n",
      "tensor(21) tensor(48.0505, dtype=torch.float64)\n",
      "tensor(13) tensor(28.4696, dtype=torch.float64)\n",
      "tensor(24) tensor(56.9674, dtype=torch.float64)\n",
      "tensor(17) tensor(39.7954, dtype=torch.float64)\n",
      "tensor(12) tensor(24.8942, dtype=torch.float64)\n",
      "tensor(13) tensor(29.8729, dtype=torch.float64)\n",
      "tensor(12) tensor(24.7964, dtype=torch.float64)\n",
      "tensor(14) tensor(32.8452, dtype=torch.float64)\n",
      "tensor(22) tensor(56.3942, dtype=torch.float64)\n",
      "tensor(13) tensor(27.6847, dtype=torch.float64)\n",
      "tensor(18) tensor(39.4514, dtype=torch.float64)\n",
      "tensor(16) tensor(38.5448, dtype=torch.float64)\n",
      "tensor(17) tensor(40.2257, dtype=torch.float64)\n",
      "tensor(17) tensor(35.0866, dtype=torch.float64)\n",
      "tensor(20) tensor(45.1426, dtype=torch.float64)\n",
      "tensor(22) tensor(47.2301, dtype=torch.float64)\n",
      "tensor(13) tensor(26.2938, dtype=torch.float64)\n",
      "tensor(12) tensor(30.5828, dtype=torch.float64)\n",
      "tensor(21) tensor(47.9672, dtype=torch.float64)\n",
      "tensor(16) tensor(39.2019, dtype=torch.float64)\n",
      "tensor(21) tensor(46.8797, dtype=torch.float64)\n",
      "tensor(17) tensor(38.6362, dtype=torch.float64)\n",
      "tensor(23) tensor(54.1136, dtype=torch.float64)\n",
      "tensor(22) tensor(49.1129, dtype=torch.float64)\n",
      "tensor(12) tensor(24.6046, dtype=torch.float64)\n",
      "tensor(15) tensor(32.1969, dtype=torch.float64)\n",
      "tensor(16) tensor(40.2158, dtype=torch.float64)\n",
      "tensor(23) tensor(53.1099, dtype=torch.float64)\n",
      "tensor(15) tensor(31.0140, dtype=torch.float64)\n",
      "tensor(13) tensor(28.7310, dtype=torch.float64)\n",
      "tensor(20) tensor(48.0334, dtype=torch.float64)\n",
      "tensor(14) tensor(29.4381, dtype=torch.float64)\n",
      "tensor(19) tensor(42.7115, dtype=torch.float64)\n",
      "tensor(19) tensor(46.1461, dtype=torch.float64)\n",
      "tensor(10) tensor(21.7815, dtype=torch.float64)\n",
      "tensor(16) tensor(34.2091, dtype=torch.float64)\n",
      "tensor(26) tensor(58.8217, dtype=torch.float64)\n",
      "tensor(15) tensor(29.8089, dtype=torch.float64)\n",
      "tensor(24) tensor(56.3765, dtype=torch.float64)\n",
      "tensor(19) tensor(42.9512, dtype=torch.float64)\n",
      "tensor(13) tensor(29.1631, dtype=torch.float64)\n",
      "tensor(17) tensor(33.4932, dtype=torch.float64)\n",
      "tensor(16) tensor(38.2584, dtype=torch.float64)\n",
      "tensor(18) tensor(35.9478, dtype=torch.float64)\n",
      "tensor(21) tensor(54.2560, dtype=torch.float64)\n",
      "tensor(22) tensor(48.4556, dtype=torch.float64)\n",
      "tensor(12) tensor(25.7649, dtype=torch.float64)\n",
      "tensor(16) tensor(34.6432, dtype=torch.float64)\n",
      "tensor(17) tensor(39.8528, dtype=torch.float64)\n",
      "tensor(12) tensor(26.5034, dtype=torch.float64)\n",
      "tensor(23) tensor(52.2134, dtype=torch.float64)\n",
      "tensor(21) tensor(48.2912, dtype=torch.float64)\n",
      "tensor(22) tensor(51.5886, dtype=torch.float64)\n",
      "tensor(11) tensor(23.0647, dtype=torch.float64)\n",
      "tensor(16) tensor(32.8416, dtype=torch.float64)\n",
      "tensor(11) tensor(25.7151, dtype=torch.float64)\n",
      "tensor(14) tensor(32.1625, dtype=torch.float64)\n",
      "tensor(30) tensor(72.0406, dtype=torch.float64)\n",
      "tensor(17) tensor(40.9763, dtype=torch.float64)\n",
      "tensor(23) tensor(58.2647, dtype=torch.float64)\n",
      "tensor(14) tensor(37.1495, dtype=torch.float64)\n",
      "tensor(19) tensor(45.1229, dtype=torch.float64)\n",
      "tensor(11) tensor(25.3070, dtype=torch.float64)\n",
      "tensor(18) tensor(40.1258, dtype=torch.float64)\n",
      "tensor(15) tensor(38.6341, dtype=torch.float64)\n",
      "tensor(15) tensor(35.0964, dtype=torch.float64)\n",
      "tensor(20) tensor(46.0312, dtype=torch.float64)\n",
      "tensor(19) tensor(44.3622, dtype=torch.float64)\n",
      "tensor(12) tensor(28.8057, dtype=torch.float64)\n",
      "tensor(13) tensor(28.5711, dtype=torch.float64)\n",
      "tensor(36) tensor(90.9486, dtype=torch.float64)\n",
      "tensor(19) tensor(42.2438, dtype=torch.float64)\n",
      "tensor(16) tensor(37.9346, dtype=torch.float64)\n",
      "tensor(13) tensor(29.6363, dtype=torch.float64)\n",
      "tensor(18) tensor(42.4146, dtype=torch.float64)\n",
      "tensor(21) tensor(52.1500, dtype=torch.float64)\n",
      "tensor(20) tensor(44.2761, dtype=torch.float64)\n",
      "tensor(25) tensor(58.6192, dtype=torch.float64)\n",
      "tensor(17) tensor(40.5523, dtype=torch.float64)\n",
      "tensor(17) tensor(37.2558, dtype=torch.float64)\n",
      "tensor(19) tensor(41.6230, dtype=torch.float64)\n",
      "tensor(22) tensor(49.5029, dtype=torch.float64)\n",
      "tensor(17) tensor(47.4297, dtype=torch.float64)\n",
      "tensor(16) tensor(34.5612, dtype=torch.float64)\n",
      "tensor(24) tensor(64.7369, dtype=torch.float64)\n",
      "tensor(13) tensor(32.9179, dtype=torch.float64)\n",
      "tensor(15) tensor(32.7324, dtype=torch.float64)\n",
      "tensor(18) tensor(38.6120, dtype=torch.float64)\n",
      "tensor(14) tensor(32.3983, dtype=torch.float64)\n",
      "tensor(29) tensor(72.5956, dtype=torch.float64)\n",
      "tensor(40) tensor(108.7233, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#note that the internal data doesn't change and your transform is only applied as you iterate through the dataset\n",
    "for x, y in test_dataset:\n",
    "    print(x.mean().long(), x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8aa698a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next up is going to be the same class where its input will be a pandas DataFrame\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/winequality-white.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ae59e853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5b205321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  20.,  163., 1457., 2198.,  880.,  180.]),\n",
       " array([3., 4., 5., 6., 7., 8., 9.]),\n",
       " <BarContainer object of 6 artists>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ys = df.values[:, -1]\n",
    "plt.hist(ys, bins=6, color='.3', histtype='bar', align='left', edgecolor='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e799e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next up is the class where its input gonna be a pandas DataFrame\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, name, df, train, transform=None, test_size=.2):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        self.name = name\n",
    "        self.df = df\n",
    "        self.xy = df.values\n",
    "        self.xtemp = torch.from_numpy(self.xy[:, :-1])\n",
    "        self.ytemp = torch.from_numpy(self.xy[:, -1])\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.test_size = test_size\n",
    "        self.x, self.y = self.split()\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        \n",
    "    def split(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.xtemp,\n",
    "                                                            self.ytemp, \n",
    "                                                            test_size=self.test_size,\n",
    "                                                            random_state=42)\n",
    "        if self.train:\n",
    "            return X_train, y_train\n",
    "        else:\n",
    "            return X_test, y_test\n",
    "    \n",
    "    def __repr__(self):\n",
    "        transform_repr = repr(self.transform) if self.transform else 'None'\n",
    "        return (f\"Dataset {self.name}\\n\"\n",
    "                f\"    Number of datapoints: {self.n_samples}\\n\"\n",
    "                f\"    Transform: {transform_repr}\")\n",
    "\n",
    "    #this should do\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c293c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(name='wine', df=df, train=True, test_size=.1)\n",
    "test_dataset = CustomDataset(name='wine', df=df, train=False, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9a38da36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9., dtype=torch.float64), tensor(3., dtype=torch.float64))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y.max(), train_dataset.y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8d51df6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2b82294a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset wine\n",
       "    Number of datapoints: 490\n",
       "    Transform: None"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "56bc8f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ac200e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c4793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2827c7b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[248], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     34\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m  DataLoader(dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 36\u001b[0m model \u001b[38;5;241m=\u001b[39m NN(input_size, num_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     38\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     41\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1154\u001b[0m             device,\n\u001b[0;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1156\u001b[0m             non_blocking,\n\u001b[0;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1158\u001b[0m         )\n\u001b[1;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1160\u001b[0m         device,\n\u001b[0;32m   1161\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1162\u001b[0m         non_blocking,\n\u001b[0;32m   1163\u001b[0m     )\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim, Tensor as t\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = 11\n",
    "num_classes = 7\n",
    "learning_rate = .001\n",
    "batch_size = 64\n",
    "num_epochs = 4\n",
    "\n",
    "train_dataset = CustomDataset(name='wine', df=df, train=True, test_size=.1)\n",
    "test_dataset = CustomDataset(name='wine', df=df, train=False, test_size=.1)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = NN(input_size, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    return num_samples, num_correct   \n",
    "\n",
    "\n",
    "def main():\n",
    "    for epoch in tqdm(range(num_epochs), desc='epoch', leave=True):    \n",
    "        for batch_idx, (data, targets) in enumerate(tqdm(train_loader, desc='training', leave=True)):\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            data = data.reshape(data.shape[0], -1)\n",
    "            optimizer.zero_grad()\n",
    "            scores = model(data)\n",
    "            targets = targets.to(torch.int64)\n",
    "            loss = criterion(scores, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "450f9002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f61fead803e4adda7d8630b6cafb8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f6e8ad40094801997997d96908282a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[247], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[243], line 65\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):    \n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m---> 65\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     66\u001b[0m         targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     68\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8da3662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "for data, targets in train_loader:\n",
    "    print(data.dtype, targets.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1816b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
